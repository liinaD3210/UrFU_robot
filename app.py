# app.py
import streamlit as st
import os
import json
from dotenv import load_dotenv
import re
from typing import List, Dict # –î–æ–±–∞–≤–∏–ª Dict –¥–ª—è —Ç–∏–ø–∏–∑–∞—Ü–∏–∏

# Langchain imports
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.chains import RetrievalQA
from langchain.schema import Document
from langchain.prompts import PromptTemplate
from langchain_core.retrievers import BaseRetriever # –ò–∑–º–µ–Ω–µ–Ω–æ –∑–¥–µ—Å—å

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è (API –∫–ª—é—á–∞)
load_dotenv()

if not os.getenv("GOOGLE_API_KEY"):
    st.error("–ù–µ –Ω–∞–π–¥–µ–Ω GOOGLE_API_KEY. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –¥–æ–±–∞–≤—å—Ç–µ –µ–≥–æ –≤ —Ñ–∞–π–ª .env")
    st.stop()

JSON_DATA_PATH = "data/programs_data.json" 

@st.cache_resource
def load_programs_data() -> tuple[List[dict], Dict[str, dict]]: # –î–æ–±–∞–≤–∏–ª —Ç–∏–ø –≤–æ–∑–≤—Ä–∞—â–∞–µ–º–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è
    if not os.path.exists(JSON_DATA_PATH):
        st.error(f"–§–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ –ø—Ä–æ–≥—Ä–∞–º–º –Ω–µ –Ω–∞–π–¥–µ–Ω: {JSON_DATA_PATH}")
        st.stop()
    with open(JSON_DATA_PATH, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    programs_search_dict: Dict[str, dict] = {} # –Ø–≤–Ω–æ —Ç–∏–ø–∏–∑–∏—Ä—É–µ–º
    for program in data:
        if "–Ω–∞–∑–≤–∞–Ω–∏–µ_–ø—Ä–æ–≥—Ä–∞–º–º—ã" in program and program["–Ω–∞–∑–≤–∞–Ω–∏–µ_–ø—Ä–æ–≥—Ä–∞–º–º—ã"]:
            # –î–æ–±–∞–≤–ª—è–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–≥—Ä–∞–º–º—ã –∏ –∫–∞–∂–¥—ã–π –ø—Ä–æ—Ñ–∏–ª—å –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –∫–ª—é—á–∏
            base_name_lower = program["–Ω–∞–∑–≤–∞–Ω–∏–µ_–ø—Ä–æ–≥—Ä–∞–º–º—ã"].lower()
            programs_search_dict[base_name_lower] = program
            
            # –ï—Å–ª–∏ –µ—Å—Ç—å –ø—Ä–æ—Ñ–∏–ª—å, –¥–æ–±–∞–≤–ª—è–µ–º –µ–≥–æ —Ç–æ–∂–µ –∫–∞–∫ –∫–ª—é—á –¥–ª—è –ø–æ–∏—Å–∫–∞
            # (–≤–æ–∑–º–æ–∂–Ω–æ, –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π —Å –±–∞–∑–æ–≤—ã–º –Ω–∞–∑–≤–∞–Ω–∏–µ–º)
            if program.get("–ø—Ä–æ—Ñ–∏–ª—å_–∏–ª–∏_—Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è"):
                profile_name_lower = program["–ø—Ä–æ—Ñ–∏–ª—å_–∏–ª–∏_—Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è"].lower()
                programs_search_dict[profile_name_lower] = program # –ü–æ–∏—Å–∫ —Ç–æ–ª—å–∫–æ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é –ø—Ä–æ—Ñ–∏–ª—è
                programs_search_dict[f"{base_name_lower} {profile_name_lower}"] = program # –ü–æ–∏—Å–∫ –ø–æ "–Ω–∞–∑–≤–∞–Ω–∏–µ + –ø—Ä–æ—Ñ–∏–ª—å"

        if "id" in program and program["id"]: # –ï—Å–ª–∏ –µ—Å—Ç—å –∫–æ–¥ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è
            programs_search_dict[program["id"]] = program
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ: –º–æ–∂–Ω–æ —Ä–∞–∑–±–∏—Ç—å –Ω–∞–∑–≤–∞–Ω–∏–µ –Ω–∞ —Å–ª–æ–≤–∞ –∏ –¥–æ–±–∞–≤–∏—Ç—å –∏—Ö –∫–∞–∫ –∫–ª—é—á–∏,
        # –Ω–æ —ç—Ç–æ –º–æ–∂–µ—Ç –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–∏–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è–º.
        # words_in_name = re.findall(r'\b\w{3,}\b', program.get("–Ω–∞–∑–≤–∞–Ω–∏–µ_–ø—Ä–æ–≥—Ä–∞–º–º—ã", "").lower())
        # for word in words_in_name:
        #     if word not in programs_search_dict: # –ß—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞—Ç—å –±–æ–ª–µ–µ —Ç–æ—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
        #         programs_search_dict[word] = program


    st.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(data)} –ø—Ä–æ–≥—Ä–∞–º–º –∏–∑ JSON. –°–æ–∑–¥–∞–Ω –ø–æ–∏—Å–∫–æ–≤—ã–π —Å–ª–æ–≤–∞—Ä—å —Å {len(programs_search_dict)} –∫–ª—é—á–∞–º–∏.")
    return data, programs_search_dict

class JsonProgramRetriever(BaseRetriever):
    programs_list: List[dict]
    programs_search_dict: dict # –°–ª–æ–≤–∞—Ä—å –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞ –ø–æ –∫–ª—é—á–∞–º
    k: int = 1 

    def _get_relevant_documents(self, query: str, *, run_manager = None) -> List[Document]:
        relevant_programs_data: List[dict] = []
        query_lower = query.lower().strip()

        # 0. –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º –ø–æ ID, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å –≤ –∑–∞–ø—Ä–æ—Å–µ - —ç—Ç–æ —Å–∞–º—ã–π —Ç–æ—á–Ω—ã–π –ø–æ–∏—Å–∫
        match_id = re.search(r'\b(\d{2}\.\d{2}\.\d{2}(?:-\w+)?)\b', query_lower) # –ò—â–µ–º –∫–æ–¥ —Ç–∏–ø–∞ XX.YY.ZZ –∏–ª–∏ XX.YY.ZZ-—Å—É—Ñ—Ñ–∏–∫—Å
        if match_id:
            program_id_from_query = match_id.group(1)
            if program_id_from_query in self.programs_search_dict:
                prog_data = self.programs_search_dict[program_id_from_query]
                if prog_data not in relevant_programs_data:
                    relevant_programs_data.append(prog_data)
        
        # 1. –ü–æ–ø—ã—Ç–∫–∞ —Ç–æ—á–Ω–æ–≥–æ/—á–∞—Å—Ç–∏—á–Ω–æ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –ø–æ –∫–ª—é—á–∞–º –≤ search_dict
        # (–∫–ª—é—á–∏: –ø–æ–ª–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è, ID, –ø—Ä–æ—Ñ–∏–ª–∏)
        if len(relevant_programs_data) < self.k:
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –∫–ª—é—á–∏ —Å–ª–æ–≤–∞—Ä—è –ø–æ –¥–ª–∏–Ω–µ –≤ –æ–±—Ä–∞—Ç–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ, —á—Ç–æ–±—ã —Å–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è—Ç—å –±–æ–ª–µ–µ –¥–ª–∏–Ω–Ω—ã–µ (—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ) –∫–ª—é—á–∏
            sorted_search_keys = sorted(self.programs_search_dict.keys(), key=len, reverse=True)
            for key_search in sorted_search_keys:
                if key_search in query_lower: 
                    program_data_val = self.programs_search_dict[key_search]
                    if program_data_val not in relevant_programs_data: 
                        relevant_programs_data.append(program_data_val)
                    if len(relevant_programs_data) >= self.k*2: # –°–æ–±–∏—Ä–∞–µ–º —á—É—Ç—å –±–æ–ª—å—à–µ, –ø–æ—Ç–æ–º –æ—Ç—Å–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
                        break 
        
        # 2. –ï—Å–ª–∏ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –ø–æ –∫–ª—é—á–∞–º –º–∞–ª–æ, –ø—Ä–æ–±—É–µ–º –±–æ–ª–µ–µ –≥–∏–±–∫–∏–π –ø–æ–∏—Å–∫ –ø–æ –æ—Ç–¥–µ–ª—å–Ω—ã–º —Å–ª–æ–≤–∞–º –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏/–ø—Ä–æ—Ñ–∏–ª–µ
        if len(relevant_programs_data) < self.k:
            query_words = set(re.findall(r'\b\w{3,}\b', query_lower)) # –°–ª–æ–≤–∞ –æ—Ç 3 –±—É–∫–≤
            
            candidate_programs = []
            for program_data_val in self.programs_list:
                if program_data_val in relevant_programs_data: continue

                # –°–æ–±–∏—Ä–∞–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞: –Ω–∞–∑–≤–∞–Ω–∏–µ + –ø—Ä–æ—Ñ–∏–ª—å + –æ–ø–∏—Å–∞–Ω–∏–µ (–ø–µ—Ä–≤—ã–µ N —Å–ª–æ–≤)
                text_to_search_in = program_data_val.get("–Ω–∞–∑–≤–∞–Ω–∏–µ_–ø—Ä–æ–≥—Ä–∞–º–º—ã", "").lower()
                if program_data_val.get("–ø—Ä–æ—Ñ–∏–ª—å_–∏–ª–∏_—Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è"):
                    text_to_search_in += " " + program_data_val["–ø—Ä–æ—Ñ–∏–ª—å_–∏–ª–∏_—Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è"].lower()
                
                # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –Ω–∞—á–∞–ª–æ –æ–ø–∏—Å–∞–Ω–∏—è –¥–ª—è –±–æ–ª–µ–µ —à–∏—Ä–æ–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞
                # description_preview = " ".join(program_data_val.get("–æ–ø–∏—Å–∞–Ω–∏–µ", "").lower().split()[:20]) # –ø–µ—Ä–≤—ã–µ 20 —Å–ª–æ–≤
                # text_to_search_in += " " + description_preview

                # –°—á–∏—Ç–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–≤–ø–∞–≤—à–∏—Ö —Å–ª–æ–≤
                matched_words_count = len(query_words.intersection(set(re.findall(r'\b\w+\b', text_to_search_in))))

                if matched_words_count > 0:
                    candidate_programs.append({"program": program_data_val, "matches": matched_words_count})
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Å–æ–≤–ø–∞–≤—à–∏—Ö —Å–ª–æ–≤
            if candidate_programs:
                sorted_candidates = sorted(candidate_programs, key=lambda x: x["matches"], reverse=True)
                for cand in sorted_candidates:
                    if cand["program"] not in relevant_programs_data:
                        relevant_programs_data.append(cand["program"])
                    if len(relevant_programs_data) >= self.k*2: # –°–æ–±–∏—Ä–∞–µ–º —á—É—Ç—å –±–æ–ª—å—à–µ
                        break
        
        # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã, —Å–æ—Ö—Ä–∞–Ω—è—è –ø–æ—Ä—è–¥–æ–∫ (—Å–Ω–∞—á–∞–ª–∞ –±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ)
        final_relevant_programs = []
        seen_ids = set()
        for prog in relevant_programs_data:
            prog_id_key = prog.get("id", str(prog)) # –£–Ω–∏–∫–∞–ª—å–Ω—ã–π –∫–ª—é—á –¥–ª—è –ø—Ä–æ–≥—Ä–∞–º–º—ã
            if prog_id_key not in seen_ids:
                final_relevant_programs.append(prog)
                seen_ids.add(prog_id_key)

        if not final_relevant_programs:
            st.warning(f"–û—Ç–ª–∞–¥–∫–∞ —Ä–µ—Ç—Ä–∏–≤–µ—Ä–∞: –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –ø—Ä–æ–≥—Ä–∞–º–º—É –ø–æ –∑–∞–ø—Ä–æ—Å—É: '{query}'")
            return [Document(page_content="–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É –æ –ø—Ä–æ–≥—Ä–∞–º–º–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö.")]

        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –ø—Ä–æ–≥—Ä–∞–º–º—ã –≤ –¥–æ–∫—É–º–µ–Ω—Ç—ã
        docs = []
        st.info(f"–û—Ç–ª–∞–¥–∫–∞ —Ä–µ—Ç—Ä–∏–≤–µ—Ä–∞: –ù–∞–π–¥–µ–Ω–æ {len(final_relevant_programs)} –ø—Ä–æ–≥—Ä–∞–º–º-–∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ '{query}'. –ë–µ—Ä–µ–º —Ç–æ–ø-{self.k}.")
        for i, program_data_item in enumerate(final_relevant_programs[:self.k]): 
            content_str = f"–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ –ø—Ä–æ–≥—Ä–∞–º–º–µ \"{program_data_item.get('–Ω–∞–∑–≤–∞–Ω–∏–µ_–ø—Ä–æ–≥—Ä–∞–º–º—ã', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}\":\n"
            if program_data_item.get('–ø—Ä–æ—Ñ–∏–ª—å_–∏–ª–∏_—Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è'):
                content_str += f"- –ü—Ä–æ—Ñ–∏–ª—å/–°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è: {program_data_item['–ø—Ä–æ—Ñ–∏–ª—å_–∏–ª–∏_—Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è']}\n"
            
            # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –ø–æ–ª—è –≤ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ –¥–ª—è –ª—É—á—à–µ–π —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
            display_order = ["id", "—Å—Ä–æ–∫_–æ–±—É—á–µ–Ω–∏—è_–ª–µ—Ç", "–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ_–ø—Ä–µ–¥–º–µ—Ç—ã", 
                             "–ø—Ä–µ–¥–º–µ—Ç—ã_–ø–æ_–≤—ã–±–æ—Ä—É_–ø—Ä–∏–º–µ—á–∞–Ω–∏–µ", "–ø—Ä–µ–¥–º–µ—Ç—ã_–ø–æ_–≤—ã–±–æ—Ä—É_–¥–µ—Ç–∞–ª–∏",
                             "–ø—Ä–æ—Ö–æ–¥–Ω–æ–π_–±–∞–ª–ª_2024", "–±—é–¥–∂–µ—Ç–Ω—ã–µ_–º–µ—Å—Ç–∞", "–æ–ø–∏—Å–∞–Ω–∏–µ"]
            
            processed_keys = set(["–Ω–∞–∑–≤–∞–Ω–∏–µ_–ø—Ä–æ–≥—Ä–∞–º–º—ã", "–ø—Ä–æ—Ñ–∏–ª—å_–∏–ª–∏_—Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è"])

            for key_item in display_order:
                if key_item in program_data_item and program_data_item[key_item] is not None:
                    value_item = program_data_item[key_item]
                    formatted_key = key_item.replace('_', ' ').capitalize()
                    
                    if key_item == "–æ–ø–∏—Å–∞–Ω–∏–µ" and isinstance(value_item, str) and len(value_item) > 300: # –°–æ–∫—Ä–∞—â–∞–µ–º –¥–ª–∏–Ω–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ
                         content_str += f"- {formatted_key}: {value_item[:300]}...\n"
                    elif isinstance(value_item, list) and value_item: # –î–ª—è —Å–ø–∏—Å–∫–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ø—Ä–µ–¥–º–µ—Ç—ã)
                        content_str += f"- {formatted_key}:\n"
                        for item_list_el in value_item:
                            if isinstance(item_list_el, dict): # –ï—Å–ª–∏ —ç–ª–µ–º–µ–Ω—Ç —Å–ø–∏—Å–∫–∞ - —Å–ª–æ–≤–∞—Ä—å
                                item_str_dict = ", ".join([f"{ik_dict.replace('_', ' ').capitalize() if ik_dict != '–Ω–∞–∑–≤–∞–Ω–∏–µ' else ''}{': ' if ik_dict != '–Ω–∞–∑–≤–∞–Ω–∏–µ' else ''}{iv_dict}" for ik_dict, iv_dict in item_list_el.items()])
                                content_str += f"  - {item_str_dict}\n"
                            else: # –ï—Å–ª–∏ —ç–ª–µ–º–µ–Ω—Ç —Å–ø–∏—Å–∫–∞ - –ø—Ä–æ—Å—Ç–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
                                content_str += f"  - {item_list_el}\n"
                    else: # –î–ª—è –æ–±—ã—á–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
                        content_str += f"- {formatted_key}: {value_item}\n"
                    processed_keys.add(key_item)

            # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø–æ–ª—è, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å –∏ –Ω–µ –±—ã–ª–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã
            for key_item, value_item in program_data_item.items():
                if key_item not in processed_keys and value_item is not None:
                    formatted_key = key_item.replace('_', ' ').capitalize()
                    content_str += f"- {formatted_key}: {value_item}\n"

            docs.append(Document(page_content=content_str, metadata={"source": "json_database", "program_name": program_data_item.get("–Ω–∞–∑–≤–∞–Ω–∏–µ_–ø—Ä–æ–≥—Ä–∞–º–º—ã")}))
            if i == 0: # –ü–µ—á–∞—Ç–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–π –Ω–∞–π–¥–µ–Ω–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
                 st.info(f"–û—Ç–ª–∞–¥–∫–∞ —Ä–µ—Ç—Ä–∏–≤–µ—Ä–∞: –ü–µ—Ä–≤—ã–π –Ω–∞–π–¥–µ–Ω–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç –¥–ª—è LLM:\n{content_str[:500]}...")
        
        return docs

    async def _aget_relevant_documents(self, query: str, *, run_manager = None) -> List[Document]:
        # –î–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é. –î–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞ –ª—É—á—à–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ.
        return self._get_relevant_documents(query, run_manager=run_manager)


@st.cache_resource
def setup_llm_and_retriever():
    programs_list, programs_search_dict = load_programs_data()
    
    custom_retriever = JsonProgramRetriever(
        programs_list=programs_list,
        programs_search_dict=programs_search_dict,
        k=1 
    )

    try:
        llm = ChatGoogleGenerativeAI(
            model="gemini-1.5-flash",
            temperature=0.2, # –ï—â–µ –Ω–∏–∂–µ –¥–ª—è —Å—Ç—Ä–æ–≥–∏—Ö –æ—Ç–≤–µ—Ç–æ–≤ –ø–æ JSON
            convert_system_message_to_human=True
        )
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ LLM Google: {e}")
        st.stop()

    prompt_template_str = """–¢—ã ‚Äî –ò–ò-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –æ—Ç–≤–µ—á–∞—é—â–∏–π –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –æ–± –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–æ–≥—Ä–∞–º–º–∞—Ö –ò–†–ò–¢-–†–¢–§.
–ò—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–æ–≥—Ä–∞–º–º–µ (–∫–æ–Ω—Ç–µ–∫—Å—Ç), —á—Ç–æ–±—ã –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å.
–ï—Å–ª–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –Ω–µ—Ç –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å, —Å–∫–∞–∂–∏: "–í –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø—Ä–æ–≥—Ä–∞–º–º–µ –Ω–µ—Ç –æ—Ç–≤–µ—Ç–∞ –Ω–∞ —ç—Ç–æ—Ç –≤–æ–ø—Ä–æ—Å." –∏–ª–∏ "–Ø –Ω–µ –Ω–∞—à–µ–ª —ç—Ç—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –æ–ø–∏—Å–∞–Ω–∏–∏ –ø—Ä–æ–≥—Ä–∞–º–º—ã."
–ù–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é. –û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.

–ö–æ–Ω—Ç–µ–∫—Å—Ç (–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–æ–≥—Ä–∞–º–º–µ):
{context}

–í–æ–ø—Ä–æ—Å: {question}
–û—Ç–≤–µ—Ç –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞:"""
    PROMPT = PromptTemplate(
        template=prompt_template_str, input_variables=["context", "question"]
    )

    chain_type_kwargs = {"prompt": PROMPT}
    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=custom_retriever, 
        return_source_documents=True,
        chain_type_kwargs=chain_type_kwargs
    )
    return qa_chain

# --- Streamlit UI ---
st.set_page_config(page_title="–ò–†–ò–¢-–†–¢–§ –ì–∏–¥ (JSON)", layout="centered")
st.title("ü§ñ –ì–∏–¥ –ø–æ –ò–†–ò–¢-–†–¢–§ (–Ω–∞ –æ—Å–Ω–æ–≤–µ JSON)")

try:
    qa_chain = setup_llm_and_retriever()
except Exception as e:
    st.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: {e}")
    st.stop() 

if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ! –ó–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å –æ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –ò–†–ò–¢-–†–¢–§."}]

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("–í–∞—à –≤–æ–ø—Ä–æ—Å (–Ω–∞–ø—Ä–∏–º–µ—Ä, '–†–∞—Å—Å–∫–∞–∂–∏ –ø—Ä–æ –†–∞–¥–∏–æ—Ç–µ—Ö–Ω–∏–∫—É' –∏–ª–∏ '–ö–∞–∫–∏–µ –ø—Ä–µ–¥–º–µ—Ç—ã –Ω–∞ 09.03.01?')..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        with st.spinner("–ò—â—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏ –¥—É–º–∞—é..."):
            try:
                result = qa_chain({"query": prompt})
                answer = result.get("result", "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç.")
                source_documents = result.get("source_documents")
                
                full_response = answer
                
                if source_documents and not (len(source_documents) == 1 and "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É –æ –ø—Ä–æ–≥—Ä–∞–º–º–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö." in source_documents[0].page_content):
                    full_response += "\n\n<details><summary>–ò—Å—Ç–æ—á–Ω–∏–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ (–¥–∞–Ω–Ω—ã–µ –ø–æ –ø—Ä–æ–≥—Ä–∞–º–º–µ):</summary>\n"
                    for doc in source_documents:
                        content_html = doc.page_content.replace('\n', '<br>') 
                        full_response += f"<p><small><i>{content_html}</i></small></p>\n"
                    full_response += "</details>"

            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞: {e}")
                full_response = f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}"
        
        message_placeholder.markdown(full_response, unsafe_allow_html=True)
    
    st.session_state.messages.append({"role": "assistant", "content": full_response})

if len(st.session_state.messages) > 1 :
    if st.button("üóëÔ∏è –û—á–∏—Å—Ç–∏—Ç—å —á–∞—Ç"):
        st.session_state.messages = [{"role": "assistant", "content": "–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ! –ó–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å –æ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –ò–†–ò–¢-–†–¢–§."}]
        st.rerun()